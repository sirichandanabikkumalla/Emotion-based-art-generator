<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Emotion-Based Art Generator</title>
  <style>
    body {
      background-color: #f4f4f9;
      font-family: "Poppins", sans-serif;
      text-align: center;
      margin-top: 60px;
    }
    h1 {
      color: #444;
      font-size: 28px;
    }
    #input-container {
      margin-top: 40px;
    }
    input {
      padding: 12px;
      width: 300px;
      border: 2px solid #888;
      border-radius: 10px;
      font-size: 16px;
      outline: none;
    }
    button {
      padding: 12px 16px;
      border: none;
      background-color: #0078ff;
      color: white;
      border-radius: 10px;
      font-size: 16px;
      margin-left: 8px;
      cursor: pointer;
    }
    button:hover {
      background-color: #005fcc;
    }
    #art-container {
      margin-top: 50px;
    }
    img {
      width: 350px;
      border-radius: 15px;
      box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
    }
    #emotion-label {
      margin-top: 20px;
      font-size: 22px;
      color: #333;
      font-weight: 600;
    }
  </style>
</head>

<body>
  <h1>üé® Emotion-Based Art Generator</h1>

  <div id="input-container">
    <input type="text" id="userInput" placeholder="Type or speak your emotion..." />
    <button onclick="startListening()">üé§ Speak</button>
    <button onclick="analyzeText()">Generate Art</button>
  </div>

  <div id="art-container">
    <p id="emotion-label"></p>
    <img id="art-image" src="" alt="" style="display: none;" />
  </div>

  <script>
    // üéôÔ∏è Voice input (Speech Recognition)
    function startListening() {
      if (!('webkitSpeechRecognition' in window)) {
        alert("Sorry, your browser doesn't support voice input.");
        return;
      }

      const recognition = new webkitSpeechRecognition();
      recognition.lang = "en-US";
      recognition.interimResults = false;
      recognition.start();

      recognition.onresult = function (event) {
        const transcript = event.results[0][0].transcript;
        document.getElementById("userInput").value = transcript;
        analyzeText(); // auto-analyze after speaking
      };

      recognition.onerror = function (event) {
        console.error(event.error);
        alert("Voice input error: " + event.error);
      };
    }

    // üß† Send text to Flask backend
    async function analyzeText() {
      const text = document.getElementById("userInput").value.trim();
      if (!text) {
        alert("Please type or speak something first!");
        return;
      }

      try {
        const response = await fetch("/analyze_text", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ text }),
        });

        const data = await response.json();

        if (data.error) {
          alert("Error: " + data.error);
          return;
        }

        document.getElementById("emotion-label").innerText =
          "Detected Emotion: " + data.emotion.toUpperCase();
        const img = document.getElementById("art-image");
        img.src = data.art_url;
        img.style.display = "block";
      } catch (error) {
        console.error(error);
        alert("Something went wrong. Check your Flask server.");
      }
    }
  </script>
</body>
</html>
